import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.preprocessing import StandardScaler
from firebase_manager import RealtimeDatabaseManager
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_absolute_error, r2_score
import warnings

warnings.filterwarnings('ignore')

"""
[Option 1: ì„¼ì„œë³„ ë…ë¦½ ëª¨ë¸]
- ì„¼ì„œ 1~4ë²ˆ ê°ê° ë³„ë„ ëª¨ë¸ í•™ìŠµ
- ì–‡ì€ ì˜· / ë‘êº¼ìš´ ì˜· íŒ¨í„´ì„ ê°œë³„ í•™ìŠµ
- ì˜ˆì¸¡ ì‹œ ê° ì„¼ì„œì— ë§ëŠ” ëª¨ë¸ ì‚¬ìš©
"""


# --------------------------------------------------------------------------
# (1) ë°ì´í„° ì¡°íšŒ
# --------------------------------------------------------------------------
def fetch_all_data_from_rtdb(key_path, db_url, base_data_path):
    """DBì—ì„œ ì „ì²´ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê°€ì ¸ì™€ ë³‘í•©"""
    try:
        rtdb_manager = RealtimeDatabaseManager(key_path, db_url)
        df = rtdb_manager.fetch_sequential_paths_as_dataframe(base_data_path)
        if df.empty: return pd.DataFrame()
        df.sort_values(by='timestamp', inplace=True)
        return df
    except Exception as e:
        print(f"RTDB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


# --------------------------------------------------------------------------
# (2) ì„¼ì„œë³„ ë°ì´í„° ë¶„ë¦¬ ì „ì²˜ë¦¬
# --------------------------------------------------------------------------
def preprocess_data_per_sensor(df_original, sensor_num,
                               session_threshold_hours=2.0,
                               dry_threshold_percent=1.0,
                               dry_stable_rows=10):
    """
    íŠ¹ì • ì„¼ì„œ ë²ˆí˜¸(1~4)ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•´ì„œ ì „ì²˜ë¦¬
    """
    if df_original.empty:
        return pd.DataFrame(), pd.Series(), [], pd.Series()

    df = df_original.copy()
    df['light_lux_avg'] = df['lux1']
    df = df.rename(columns={'temperature': 'ambient_temp', 'humidity': 'ambient_humidity'})
    df = df.sort_values(by='timestamp').reset_index(drop=True)

    # ì„¸ì…˜ ID ìƒì„±
    time_diff = df['timestamp'].diff().dt.total_seconds() / 3600
    df['session_id'] = (time_diff > session_threshold_hours).cumsum()

    sensor_col = f'moisture_percent_{sensor_num}'
    all_sensor_data = []

    # ê° ì„¸ì…˜ë³„ë¡œ ì²˜ë¦¬
    for session_id in df['session_id'].unique():
        session_df = df[df['session_id'] == session_id].copy()

        sub_df = session_df[[
            'timestamp', 'ambient_temp', 'ambient_humidity', 'light_lux_avg', sensor_col
        ]].copy()

        sub_df = sub_df.rename(columns={sensor_col: 'current_humidity'})

        # ê±´ì¡° ì™„ë£Œ ì‹œì  íƒì§€
        is_dry = sub_df['current_humidity'] < dry_threshold_percent
        is_stable_dry = is_dry.rolling(window=dry_stable_rows).sum() >= dry_stable_rows
        stable_indices = np.where(is_stable_dry)[0]

        if len(stable_indices) > 0:
            dry_idx = stable_indices[0] - dry_stable_rows + 1
            true_end_time = sub_df.iloc[dry_idx]['timestamp']
            sub_df = sub_df[sub_df['timestamp'] <= true_end_time].copy()

            # ë‚¨ì€ ì‹œê°„ ê³„ì‚°
            sub_df['remaining_time_minutes'] = (true_end_time - sub_df['timestamp']).dt.total_seconds() / 60

            # í”¼ì²˜ ìƒì„±
            sub_df['delta_humidity'] = sub_df['current_humidity'].diff().fillna(0)
            sub_df['delta_illumination'] = sub_df['light_lux_avg'].diff().fillna(0)
            sub_df['humidity_trend'] = sub_df['current_humidity'].rolling(3).mean().bfill()
            sub_df['humidity_variance'] = sub_df['current_humidity'].rolling(5).std().fillna(0)

            # ê²½ê³¼ ì‹œê°„
            start_time = sub_df['timestamp'].iloc[0]
            sub_df['time_elapsed'] = (sub_df['timestamp'] - start_time).dt.total_seconds() / 60

            # ì´ˆê¸° ìŠµë„ (ì„¼ì„œë³„ íŠ¹ì„±)
            sub_df['initial_humidity'] = sub_df['current_humidity'].iloc[0]

            sub_df['session_id'] = session_id
            all_sensor_data.append(sub_df)

    if not all_sensor_data:
        return pd.DataFrame(), pd.Series(), [], pd.Series()

    processed_df = pd.concat(all_sensor_data, ignore_index=True)

    features = [
        'ambient_temp', 'ambient_humidity', 'light_lux_avg',
        'current_humidity', 'delta_humidity', 'delta_illumination',
        'humidity_trend', 'humidity_variance', 'time_elapsed', 'initial_humidity'
    ]
    target = 'remaining_time_minutes'

    processed_df = processed_df.dropna(subset=features + [target])

    X = processed_df[features]
    y = processed_df[target]
    groups = processed_df['session_id']

    return X, y, features, groups


# --------------------------------------------------------------------------
# (3) ì„¼ì„œë³„ ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------------------------------
def train_sensor_model(X, y, groups, sensor_num):
    """íŠ¹ì • ì„¼ì„œìš© ëª¨ë¸ í•™ìŠµ"""
    if X.empty:
        print(f"   âŒ ì„¼ì„œ {sensor_num}: ë°ì´í„° ì—†ìŒ")
        return None, None

    print(f"\n   ğŸ”§ ì„¼ì„œ {sensor_num} ëª¨ë¸ í•™ìŠµ ì¤‘...")
    print(f"      ìƒ˜í”Œ ìˆ˜: {len(X)}ê°œ")

    # Train/Val ë¶„ë¦¬
    unique_sessions = groups.unique()
    n_sessions = len(unique_sessions)

    print(f"      ì„¸ì…˜ ìˆ˜: {n_sessions}ê°œ")

    if n_sessions < 3:
        print(f"      âš ï¸  ì„¸ì…˜ ë¶€ì¡± â†’ ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ")
        use_validation = False
        X_train = X
        y_train = y
    else:
        use_validation = True
        np.random.seed(42)
        shuffled_sessions = np.random.permutation(unique_sessions)
        split_point = int(len(shuffled_sessions) * 0.8)

        train_sessions = shuffled_sessions[:split_point]
        val_sessions = shuffled_sessions[split_point:]

        train_mask = groups.isin(train_sessions)
        val_mask = groups.isin(val_sessions)

        X_train, X_val = X[train_mask], X[val_mask]
        y_train, y_val = y[train_mask], y[val_mask]

    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)

    if use_validation:
        X_val_scaled = scaler.transform(X_val)

    # ëª¨ë¸ í•™ìŠµ
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_estimators=250,
        learning_rate=0.05,
        max_depth=4,
        gamma=3.0,
        min_child_weight=10,
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=0.5,
        reg_lambda=1.5,
        random_state=42
    )

    if use_validation:
        model.fit(
            X_train_scaled, y_train,
            eval_set=[(X_val_scaled, y_val)],
            verbose=False
        )

        # ì„±ëŠ¥ í‰ê°€
        y_train_pred = model.predict(X_train_scaled)
        y_val_pred = model.predict(X_val_scaled)

        train_mae = mean_absolute_error(y_train, y_train_pred)
        val_mae = mean_absolute_error(y_val, y_val_pred)

        print(f"      ğŸ“Š Train MAE: {train_mae:.1f}ë¶„ | Val MAE: {val_mae:.1f}ë¶„")

        if val_mae - train_mae > 80:
            print(f"      âš ï¸  ê³¼ì í•© ì˜ì‹¬ (ì°¨ì´ {val_mae - train_mae:.1f}ë¶„)")
        else:
            print(f"      âœ… ê´œì°®ìŒ (ì°¨ì´ {val_mae - train_mae:.1f}ë¶„)")
    else:
        model.fit(X_train_scaled, y_train, verbose=False)
        train_mae = mean_absolute_error(y_train, model.predict(X_train_scaled))
        print(f"      ğŸ“Š Train MAE: {train_mae:.1f}ë¶„")

    return model, scaler


# --------------------------------------------------------------------------
# (4) ì „ì²´ ì„¼ì„œ ëª¨ë¸ ìƒì„± ë° ì €ì¥
# --------------------------------------------------------------------------
def create_all_sensor_models(raw_df):
    """ì„¼ì„œ 1~4ë²ˆ ëª¨ë¸ì„ ê°ê° í•™ìŠµ"""
    print("\n" + "=" * 60)
    print("ğŸš€ ì„¼ì„œë³„ ë…ë¦½ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("=" * 60)

    models = {}
    scalers = {}
    features_list = None

    for sensor_num in range(1, 5):
        print(f"\nğŸ“ ì„¼ì„œ {sensor_num} ì²˜ë¦¬ ì¤‘...")

        X, y, feats, groups = preprocess_data_per_sensor(
            raw_df, sensor_num,
            session_threshold_hours=2.0,
            dry_threshold_percent=1.0
        )

        if not X.empty:
            model, scaler = train_sensor_model(X, y, groups, sensor_num)

            if model is not None:
                models[sensor_num] = model
                scalers[sensor_num] = scaler
                features_list = feats

                # ê°œë³„ ì €ì¥
                joblib.dump(model, f'sensor_{sensor_num}_model.pkl')
                joblib.dump(scaler, f'sensor_{sensor_num}_scaler.pkl')
        else:
            print(f"   âŒ ì„¼ì„œ {sensor_num}: ì „ì²˜ë¦¬ ì‹¤íŒ¨")

    # í†µí•© ì €ì¥
    if models:
        joblib.dump({
            'models': models,
            'scalers': scalers,
            'features': features_list
        }, 'all_sensors_bundle.pkl')

        print("\n" + "=" * 60)
        print(f"ğŸ’¾ ì´ {len(models)}ê°œ ì„¼ì„œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        print("   - sensor_1_model.pkl ~ sensor_4_model.pkl")
        print("   - all_sensors_bundle.pkl (í†µí•© íŒŒì¼)")
        print("=" * 60)

    return models, scalers, features_list


# --------------------------------------------------------------------------
# (5) ì‹¤ì‹œê°„ ì˜ˆì¸¡ìš© í•¨ìˆ˜ (ì„¼ì„œë³„ ëª¨ë¸ ì‚¬ìš©)
# --------------------------------------------------------------------------
def predict_with_sensor_models(current_session_df, models, scalers, features_list):
    """ì„¼ì„œë³„ ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°ê° ì˜ˆì¸¡"""
    if len(current_session_df) < 5:
        print("âš ï¸  ì˜ˆì¸¡ì— ìµœì†Œ 5ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

    df = current_session_df.copy()
    df['light_lux_avg'] = df['lux1']
    df = df.rename(columns={'temperature': 'ambient_temp', 'humidity': 'ambient_humidity'})

    latest_rows = df.tail(5)
    predictions = {}

    sensor_cols = {
        1: 'moisture_percent_1',
        2: 'moisture_percent_2',
        3: 'moisture_percent_3',
        4: 'moisture_percent_4'
    }

    for sensor_num, sensor_col in sensor_cols.items():
        if sensor_num not in models:
            print(f"   âš ï¸  ì„¼ì„œ {sensor_num} ëª¨ë¸ ì—†ìŒ")
            continue

        # í”¼ì²˜ ìƒì„±
        latest = latest_rows.iloc[-1]
        prev1 = latest_rows.iloc[-2]

        curr_hum = latest[sensor_col]
        prev_hum = prev1[sensor_col]

        delta_hum = curr_hum - prev_hum
        delta_lux = latest['light_lux_avg'] - prev1['light_lux_avg']

        humidity_values = latest_rows[sensor_col].values
        trend = np.mean(humidity_values[-3:])
        variance = np.std(humidity_values)

        start_time = latest_rows['timestamp'].iloc[0]
        time_elapsed = (latest['timestamp'] - start_time).total_seconds() / 60
        initial_hum = latest_rows[sensor_col].iloc[0]

        input_data = pd.DataFrame([{
            'ambient_temp': latest['ambient_temp'],
            'ambient_humidity': latest['ambient_humidity'],
            'light_lux_avg': latest['light_lux_avg'],
            'current_humidity': curr_hum,
            'delta_humidity': delta_hum,
            'delta_illumination': delta_lux,
            'humidity_trend': trend,
            'humidity_variance': variance,
            'time_elapsed': time_elapsed,
            'initial_humidity': initial_hum
        }])[features_list]

        # ì˜ˆì¸¡
        scaled = scalers[sensor_num].transform(input_data)
        pred = models[sensor_num].predict(scaled)[0]
        pred = max(0, pred)  # ìŒìˆ˜ ë°©ì§€

        # ğŸ”§ ìƒì‹ ê¸°ë°˜ ë³´ì • (í•µì‹¬!)
        if curr_hum < 2.0:  # ê±°ì˜ ë§ˆë¦„
            if delta_hum >= 0:  # ë” ë§ˆë¥´ì§€ ì•ŠìŒ
                pred = 0  # ì¦‰ì‹œ ì™„ë£Œ
                print(f"   âœ… ì„¼ì„œ {sensor_num}: ì´ë¯¸ ê±´ì¡° ì™„ë£Œ (ìŠµë„ {curr_hum:.1f}%)")
            else:  # ì•½ê°„ ë§ˆë¥´ëŠ” ì¤‘
                pred = min(pred, 20)  # ìµœëŒ€ 20ë¶„
                print(f"   ğŸ”§ ì„¼ì„œ {sensor_num}: ê±°ì˜ ì™„ë£Œ, ì˜ˆì¸¡ ì¡°ì • â†’ {int(pred)}ë¶„")

        elif curr_hum < 5.0 and delta_hum >= -0.5:  # 5% ì´í•˜ì¸ë° ë³€í™” ì—†ìŒ
            pred = min(pred, 60)  # ìµœëŒ€ 1ì‹œê°„
            print(f"   ğŸ”§ ì„¼ì„œ {sensor_num}: ìŠµë„ ë‚®ìŒ, ì˜ˆì¸¡ ì¡°ì • â†’ {int(pred)}ë¶„")

        predictions[sensor_num] = pred

    return predictions


# --------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ë¶€
# --------------------------------------------------------------------------
if __name__ == '__main__':
    KEY_PATH = "firebase.json"
    DB_URL = "https://smart-drying-rack-fe271-default-rtdb.firebaseio.com/"
    BASE_PATH = "drying-rack"

    print("\nğŸš€ ì„¼ì„œë³„ ë…ë¦½ ëª¨ë¸ í•™ìŠµ ì‹œìŠ¤í…œ\n")

    # 1. ë°ì´í„° ë¡œë“œ
    raw_df = fetch_all_data_from_rtdb(KEY_PATH, DB_URL, BASE_PATH)

    if raw_df.empty:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    # 2. ì„¼ì„œë³„ ëª¨ë¸ í•™ìŠµ
    models, scalers, features = create_all_sensor_models(raw_df)

    if not models:
        print("âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
        exit()

    # 3. íƒ€ì„ë¨¸ì‹  í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 60)
    print("â° íƒ€ì„ë¨¸ì‹  ì‹œë®¬ë ˆì´ì…˜ (ì„¼ì„œë³„ ë…ë¦½ ëª¨ë¸)")
    print("=" * 60)

    try:
        # ëª¨ë¸ ë¡œë“œ
        bundle = joblib.load('all_sensors_bundle.pkl')
        loaded_models = bundle['models']
        loaded_scalers = bundle['scalers']
        loaded_features = bundle['features']

        # ë§ˆì§€ë§‰ ì„¸ì…˜ ì¶”ì¶œ
        df_sim = raw_df.copy().sort_values(by='timestamp')
        time_diff = df_sim['timestamp'].diff().dt.total_seconds() / 3600
        df_sim['session_id'] = (time_diff > 2.0).cumsum()

        last_session_id = df_sim['session_id'].max()
        last_session_df = df_sim[df_sim['session_id'] == last_session_id].copy().reset_index(drop=True)

        if len(last_session_df) > 10:
            test_index = len(last_session_df) // 2
            start_time = last_session_df['timestamp'].iloc[0]
            current_data_slice = last_session_df.iloc[max(0, test_index - 5): test_index]
            current_timestamp = current_data_slice['timestamp'].iloc[-1]

            elapsed_minutes = (current_timestamp - start_time).total_seconds() / 60

            moist_cols = ['moisture_percent_1', 'moisture_percent_2',
                          'moisture_percent_3', 'moisture_percent_4']
            current_humidities = current_data_slice.iloc[-1][moist_cols]

            print(f"\nâ±  í˜„ì¬ ì‹œì : {int(elapsed_minutes)}ë¶„ ê²½ê³¼")
            print(f"ğŸ’§ ì„¼ì„œë³„ í˜„ì¬ ìŠµë„:")
            for i, col in enumerate(moist_cols, 1):
                print(f"   ì„¼ì„œ {i}: {current_humidities[col]:.1f}%")

            # ì„¼ì„œë³„ ì˜ˆì¸¡
            predictions = predict_with_sensor_models(
                current_data_slice, loaded_models, loaded_scalers, loaded_features
            )

            if predictions:
                print(f"\nğŸ¤– ì„¼ì„œë³„ AI ì˜ˆì¸¡:")
                for sensor_num, pred in predictions.items():
                    print(f"   ì„¼ì„œ {sensor_num}: {int(pred)}ë¶„")

                # ì‹¤ì œ ì •ë‹µ (ì„¼ì„œë³„)
                real_end_time = last_session_df['timestamp'].max()
                real_remaining = (real_end_time - current_timestamp).total_seconds() / 60

                print(f"\nğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
                pred_values = list(predictions.values())
                final_pred = max(pred_values)

                print(f"   ìµœì¢… ì˜ˆì¸¡ (MAX): {int(final_pred)}ë¶„")
                print(f"   ì‹¤ì œ ì •ë‹µ: {int(real_remaining)}ë¶„")
                print(f"   ì˜¤ì°¨: {int(abs(final_pred - real_remaining))}ë¶„")
                print(f"   ì •í™•ë„: {100 - abs(final_pred - real_remaining) / real_remaining * 100:.1f}%")

                # ì„¼ì„œë³„ í¸ì°¨ ë¶„ì„
                pred_std = np.std(pred_values)
                print(f"\n   ì˜ˆì¸¡ í‘œì¤€í¸ì°¨: {pred_std:.1f}ë¶„")

                if pred_std > 100:
                    print(f"   âš ï¸  ì„¼ì„œ ê°„ í¸ì°¨ í¼ â†’ ì˜·ê° íŠ¹ì„± ì°¨ì´ ë°˜ì˜ë¨")
                else:
                    print(f"   âœ… ì„¼ì„œ ê°„ í¸ì°¨ ì‘ìŒ â†’ ê· ì¼í•œ ê±´ì¡°")

                print("=" * 60)

        else:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()