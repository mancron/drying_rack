import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.preprocessing import StandardScaler
from firebase_manager import RealtimeDatabaseManager
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

"""
[Method 2: ê°œë³„ ì„¼ì„œ ë…ë¦½ ì˜ˆì¸¡ ë°©ì‹]
Firebase DBì—ì„œ ì„¼ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê° ì„¼ì„œ(1~4ë²ˆ)ë¥¼ ë…ë¦½ì ì¸ ê±´ì¡° ì‚¬ê±´ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.
ì˜ˆì¸¡ ì‹œì—ëŠ” 4ê°œ ì„¼ì„œì˜ ì˜ˆìƒ ì¢…ë£Œ ì‹œê°„ì„ ê°ê° êµ¬í•œ ë’¤, ê·¸ ì¤‘ ê°€ì¥ ëŠ¦ê²Œ ëë‚˜ëŠ” ì‹œê°„(Max)ì„ ìµœì¢… ê²°ê³¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""


# --------------------------------------------------------------------------
# (1) ë°ì´í„° ì¡°íšŒ ë° ì „ì²˜ë¦¬
# --------------------------------------------------------------------------

def fetch_all_data_from_rtdb(key_path, db_url, base_data_path):
    """DBì—ì„œ ì „ì²´ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê°€ì ¸ì™€ ë³‘í•©"""
    try:
        rtdb_manager = RealtimeDatabaseManager(key_path, db_url)
        df = rtdb_manager.fetch_sequential_paths_as_dataframe(base_data_path)
        if df.empty: return pd.DataFrame()
        df.sort_values(by='timestamp', inplace=True)
        return df
    except Exception as e:
        print(f"RTDB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


def preprocess_data_independent_sensors(df_original,
                                        session_threshold_hours=1.0,
                                        dry_threshold_percent=1.0,
                                        dry_stable_rows=10):
    """
    (í•µì‹¬ ìˆ˜ì •) ì„¼ì„œ 1~4ë²ˆì„ ë…ë¦½ì ì¸ ë°ì´í„°ë¡œ ìª¼ê°œì„œ í•™ìŠµ ë°ì´í„°ë¥¼ 4ë°°ë¡œ ëŠ˜ë¦¼.
    ê° ì„¼ì„œë³„ë¡œ 'ìê¸°ê°€ ë§ˆë¥´ëŠ” ì‹œê°„'ì„ ì •ë‹µ(Target)ìœ¼ë¡œ ì„¤ì •í•¨.
    """
    if df_original.empty:
        return pd.DataFrame(), pd.Series(), [], pd.Series()

    df = df_original.copy()

    # 1. ì»¬ëŸ¼ëª… í‘œì¤€í™”
    df['light_lux_avg'] = df['lux1']
    df = df.rename(columns={'temperature': 'ambient_temp', 'humidity': 'ambient_humidity'})
    df = df.sort_values(by='timestamp').reset_index(drop=True)

    # 2. ì„¸ì…˜ ID ìƒì„±
    time_diff = df['timestamp'].diff().dt.total_seconds() / 3600
    df['session_id'] = (time_diff > session_threshold_hours).cumsum()

    print(f"ì´ {df['session_id'].nunique()}ê°œì˜ ê±´ì¡° ì„¸ì…˜ ê°ì§€. (ì´ì œ ê° ì„¸ì…˜ì„ 4ê°œë¡œ ìª¼ê°­ë‹ˆë‹¤)")

    sensor_columns = [
        'moisture_percent_1', 'moisture_percent_2',
        'moisture_percent_3', 'moisture_percent_4'
    ]

    all_sensor_data = []

    # 3. [ì´ì¤‘ ë£¨í”„] ê° ì„¸ì…˜ ì•ˆì—ì„œ -> ê° ì„¼ì„œë³„ë¡œ ë°ì´í„°ë¥¼ ë”°ë¡œ ë½‘ì•„ëƒ„
    for session_id in df['session_id'].unique():
        session_full_df = df[df['session_id'] == session_id].copy()

        for sensor_col in sensor_columns:
            # í•´ë‹¹ ì„¼ì„œ ë°ì´í„°ë§Œ ë½‘ì•„ì„œ ì„ì‹œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            # (ì£¼ë³€ í™˜ê²½ ì •ë³´ëŠ” ê³µí†µìœ¼ë¡œ ê°€ì ¸ê°)
            sub_df = session_full_df[[
                'timestamp', 'ambient_temp', 'ambient_humidity', 'light_lux_avg',
                sensor_col  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì„¼ì„œ ê°’ë§Œ ê°€ì ¸ì˜´
            ]].copy()

            # ì»¬ëŸ¼ëª…ì„ í†µì¼ (ëª¨ë¸ì€ ì–´ëŠ ì„¼ì„œì¸ì§€ ëª¨ë¥´ê³  'current_humidity'ë¡œë§Œ ì•Œê²Œ ë¨)
            sub_df = sub_df.rename(columns={sensor_col: 'current_humidity'})

            # --- ê°œë³„ ì„¼ì„œì˜ ê±´ì¡° ì™„ë£Œ ì‹œì  íƒì§€ ---
            is_dry = sub_df['current_humidity'] < dry_threshold_percent
            is_stable_dry = is_dry.rolling(window=dry_stable_rows).sum() >= dry_stable_rows
            stable_indices = np.where(is_stable_dry)[0]

            if len(stable_indices) > 0:
                # ì´ ì„¼ì„œê°€ ë§ˆë¥¸ ì‹œì 
                dry_idx = stable_indices[0] - dry_stable_rows + 1
                true_end_time = sub_df.iloc[dry_idx]['timestamp']

                # ë§ˆë¥¸ ì‹œì  ì´í›„ ë°ì´í„°ëŠ” ìë¦„ (í•™ìŠµ ë°©í•´ ê¸ˆì§€)
                sub_df = sub_df[sub_df['timestamp'] <= true_end_time].copy()

                # yê°’(ë‚¨ì€ ì‹œê°„) ê³„ì‚°
                sub_df['remaining_time_minutes'] = (true_end_time - sub_df['timestamp']).dt.total_seconds() / 60

                # í”¼ì²˜ ìƒì„± (ë³€í™”ëŸ‰, ì¶”ì„¸)
                sub_df['delta_humidity'] = sub_df['current_humidity'].diff().fillna(0)
                sub_df['delta_illumination'] = sub_df['light_lux_avg'].diff().fillna(0)
                sub_df['humidity_trend'] = sub_df['current_humidity'].rolling(3).mean().bfill()

                # ê·¸ë£¹ ë¶„ë¦¬ë¥¼ ìœ„í•œ ID (ì„¸ì…˜ID ìœ ì§€)
                sub_df['session_id'] = session_id

                all_sensor_data.append(sub_df)

            else:
                # ì´ ì„¼ì„œëŠ” ëê¹Œì§€ ì•ˆ ë§ˆë¦„ -> í•™ìŠµì—ì„œ ì œì™¸í•˜ê±°ë‚˜ ì „ì²´ ì‹œê°„ì„ ì •ë‹µìœ¼ë¡œ ì”€
                # (ì—¬ê¸°ì„œëŠ” í’ˆì§ˆì„ ìœ„í•´ ì œì™¸)
                pass

    if not all_sensor_data:
        print("ìœ íš¨í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), pd.Series(), [], pd.Series()

    # 4. ë°ì´í„° í•©ì¹˜ê¸°
    processed_df = pd.concat(all_sensor_data, ignore_index=True)

    features = [
        'ambient_temp', 'ambient_humidity', 'light_lux_avg',
        'current_humidity', 'delta_humidity', 'delta_illumination', 'humidity_trend'
    ]
    target = 'remaining_time_minutes'

    processed_df = processed_df.dropna(subset=features + [target])

    X = processed_df[features]
    y = processed_df[target]
    groups = processed_df['session_id']  # ì„¸ì…˜ ë‹¨ìœ„ ë¶„í• ì„ ìœ„í•´ í•„ìš”

    print(f"ë°ì´í„° ë»¥íŠ€ê¸° ì™„ë£Œ: ì´ {len(processed_df)}ê°œ ìƒ˜í”Œ ìƒì„± (ì›ë³¸ ëŒ€ë¹„ ì•½ 4ë°°)")
    return X, y, features, groups


# --------------------------------------------------------------------------
# (2) ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------------------------------
# ìˆ˜ì •ëœ create_and_save_model (í…ŒìŠ¤íŠ¸ìš©)
def create_and_save_model(X, y, groups):
    if X.empty: return None
    print("\n--- [ì½”ë“œ ê²€ì¦ìš©] ì „ì²´ ë°ì´í„° í•™ìŠµ í…ŒìŠ¤íŠ¸ ---")

    # 1. ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì§€ ì•Šê³  í†µì§¸ë¡œ ì”ë‹ˆë‹¤.
    X_train = X
    y_train = y

    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)

    # ëª¨ë¸ í•™ìŠµ
    model = xgb.XGBRegressor(
        objective='reg:squarederror', n_estimators=500, learning_rate=0.05,
        max_depth=5, random_state=42
    )
    model.fit(X_train_scaled, y_train)

    # 2. í•™ìŠµí•œ ë°ì´í„°ë¡œ ë°”ë¡œ ì±„ì  (ìê°€ ì±„ì )
    y_pred = model.predict(X_train_scaled)

    r2 = r2_score(y_train, y_pred)
    mae = mean_absolute_error(y_train, y_pred)

    print(f"\n[ìê°€ ì±„ì  ê²°ê³¼ (Train Score)]")
    print(f"RÂ² Score: {r2:.4f} (ì´ ì ìˆ˜ê°€ 0.9 ì´ìƒ ë‚˜ì™€ì•¼ ì½”ë“œê°€ ì •ìƒ)")
    print(f"MAE: {mae:.2f}ë¶„")

    # (ì´í•˜ ì €ì¥ ë¡œì§ì€ ìœ ì§€)
    joblib.dump(model, 'drying_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')

    return model



# --------------------------------------------------------------------------
# (3) ì‹¤ì‹œê°„ ì˜ˆì¸¡ìš© í•¨ìˆ˜ (4ê°œ ì„¼ì„œ ê°ê° ì˜ˆì¸¡ í›„ MAX)
# --------------------------------------------------------------------------

def make_features_for_independent_prediction(current_session_df, features_list):
    """ìµœì‹  ë°ì´í„°(3í–‰)ë¥¼ ë°›ì•„ 4ê°œì˜ í”¼ì²˜ ì„¸íŠ¸(ì„¼ì„œ 1~4ìš©)ë¥¼ ë§Œë“­ë‹ˆë‹¤."""
    if len(current_session_df) < 3: return None

    df = current_session_df.copy()

    # ê³µí†µ ì»¬ëŸ¼ ì •ë¦¬
    df['light_lux_avg'] = df['lux1']
    df = df.rename(columns={'temperature': 'ambient_temp', 'humidity': 'ambient_humidity'})

    latest_rows = df.tail(3)  # ë§ˆì§€ë§‰ 3ê°œ

    input_batch = []  # ëª¨ë¸ì— ë„£ì„ 4ê°œì˜ í–‰

    sensor_cols = ['moisture_percent_1', 'moisture_percent_2', 'moisture_percent_3', 'moisture_percent_4']

    for sensor in sensor_cols:
        # ê° ì„¼ì„œë¥¼ 'current_humidity'ë¡œ ê°„ì£¼í•˜ê³  í”¼ì²˜ ê³„ì‚°
        latest = latest_rows.iloc[-1]
        prev1 = latest_rows.iloc[-2]
        prev2 = latest_rows.iloc[-3]

        curr_hum = latest[sensor]
        prev_hum = prev1[sensor]
        prev2_hum = prev2[sensor]

        # í”¼ì²˜ ê³„ì‚°
        delta_hum = curr_hum - prev_hum
        delta_lux = latest['light_lux_avg'] - prev1['light_lux_avg']
        trend = (curr_hum + prev_hum + prev2_hum) / 3

        row = {
            'ambient_temp': latest['ambient_temp'],
            'ambient_humidity': latest['ambient_humidity'],
            'light_lux_avg': latest['light_lux_avg'],
            'current_humidity': curr_hum,
            'delta_humidity': delta_hum,
            'delta_illumination': delta_lux,
            'humidity_trend': trend
        }
        input_batch.append(row)

    return pd.DataFrame(input_batch)[features_list]  # ìˆœì„œ ë§ì¶°ì„œ ë°˜í™˜


# --------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ë¶€ (ìˆ˜ì •ë¨: ê³¼ê±° íŠ¹ì • ì‹œì ìœ¼ë¡œ ëŒì•„ê°€ì„œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸)
# --------------------------------------------------------------------------
if __name__ == '__main__':
    KEY_PATH = "firebase.json"
    DB_URL = "https://smart-drying-rack-fe271-default-rtdb.firebaseio.com/"
    BASE_PATH = "drying-rack"

    # 1. í•™ìŠµ ë‹¨ê³„
    raw_df = fetch_all_data_from_rtdb(KEY_PATH, DB_URL, BASE_PATH)

    if not raw_df.empty:
        # ì „ì²˜ë¦¬ ë° ëª¨ë¸ í•™ìŠµ
        X, y, feats, groups = preprocess_data_independent_sensors(
            raw_df, session_threshold_hours=2.0, dry_threshold_percent=1.0
        )
        model = create_and_save_model(X, y, groups)
    else:
        print("ë°ì´í„° ì—†ìŒ")
        exit()

    # 2. ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ (íƒ€ì„ë¨¸ì‹  í…ŒìŠ¤íŠ¸)
    print("\n--- ì‹œë®¬ë ˆì´ì…˜ (ê³¼ê±° ì‹œì  í…ŒìŠ¤íŠ¸) ---")
    try:
        loaded_model = joblib.load('drying_model.pkl')
        loaded_scaler = joblib.load('scaler.pkl')

        if not raw_df.empty:
            # (1) ë§ˆì§€ë§‰ ì„¸ì…˜ ì¶”ì¶œ
            df_sim = raw_df.copy().sort_values(by='timestamp')
            time_diff = df_sim['timestamp'].diff().dt.total_seconds() / 3600
            df_sim['session_id'] = (time_diff > 2.0).cumsum()

            last_session_id = df_sim['session_id'].max()
            last_session_df = df_sim[df_sim['session_id'] == last_session_id].copy().reset_index(drop=True)

            # ----------------------------------------------------------------
            # [â˜… í•µì‹¬ ìˆ˜ì •] ë§¨ ë(tail)ì´ ì•„ë‹ˆë¼, "ì¤‘ê°„ ì§€ì "ì„ ê°•ì œë¡œ ì„ íƒ
            # ì˜ˆ: ì „ì²´ ë°ì´í„°ì˜ 50% ì§€ì  (í•œì°½ ê±´ì¡° ì¤‘ì¼ ë•Œ)
            # ----------------------------------------------------------------
            test_index = len(last_session_df) // 2  # ë”± ì¤‘ê°„ ì§€ì 

            # ë§Œì•½ íŠ¹ì • ìŠµë„ ì‹œì ì„ ì°¾ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ:
            # test_index = (last_session_df['moisture_percent_1'] < 30).idxmax() # ìŠµë„ê°€ 30% ë°‘ìœ¼ë¡œ ë–¨ì–´ì§€ê¸° ì§ì „

            start_time = last_session_df['timestamp'].iloc[0]  # ì„¸ì…˜ ì‹œì‘ ì‹œê°„

            # "ê·¸ ë‹¹ì‹œ"ë¼ê³  ê°€ì •í•˜ê³  ë°ì´í„° 3ê°œë§Œ ì˜ë¼ëƒ„
            current_data_slice = last_session_df.iloc[test_index - 3: test_index]
            current_timestamp = current_data_slice['timestamp'].iloc[-1]

            # (2) í˜„ì¬ ìƒíƒœ ì¶œë ¥
            elapsed_minutes = (current_timestamp - start_time).total_seconds() / 60

            moist_cols = ['moisture_percent_1', 'moisture_percent_2', 'moisture_percent_3', 'moisture_percent_4']
            current_humidity_avg = current_data_slice.iloc[-1][moist_cols].mean()

            print(f"â± [íƒ€ì„ë¨¸ì‹ ] í˜„ì¬ ì‹œì : ì„¸ì…˜ ì‹œì‘ í›„ {int(elapsed_minutes)}ë¶„ ê²½ê³¼")
            print(f"ğŸ’§ í˜„ì¬ í‰ê·  ìŠµë„: {current_humidity_avg:.1f}% (í•œì°½ ê±´ì¡° ì¤‘)")

            # (3) ì˜ˆì¸¡ ìˆ˜í–‰
            batch_inputs = make_features_for_independent_prediction(current_data_slice, feats)

            if batch_inputs is not None:
                scaled_inputs = loaded_scaler.transform(batch_inputs)
                preds = loaded_model.predict(scaled_inputs)

                final_time = max(preds)
                final_time = max(0, final_time)

                print("-" * 30)
                print(f"ê° ì„¼ì„œë³„ ì˜ˆì¸¡(ë¶„): {preds}")
                print(f"âœ… AI ì˜ˆì¸¡: ì•ìœ¼ë¡œ {int(final_time)}ë¶„ ë” ëŒë©´ ë§ˆë¦…ë‹ˆë‹¤.")
                print("-" * 30)

                # (ì°¸ê³ ) ì‹¤ì œ ì •ë‹µ í™•ì¸ (ë¯¸ë˜ë¥¼ ë¯¸ë¦¬ ë³´ê¸°)
                real_end_time = last_session_df['timestamp'].max()
                real_remaining = (real_end_time - current_timestamp).total_seconds() / 60
                print(f"ğŸ‘€ (ì •ë‹µì§€ í™•ì¸) ì‹¤ì œë¡œëŠ” {int(real_remaining)}ë¶„ ë’¤ì— ëë‚¬ìŠµë‹ˆë‹¤.")
                print(f"ğŸ¯ ì˜¤ì°¨: {int(abs(final_time - real_remaining))}ë¶„")

    except Exception as e:
        print(f"ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")